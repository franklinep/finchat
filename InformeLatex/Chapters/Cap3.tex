\chapter{Metodología y arquitectura propuesta}
\label{cap:metodologia}

\section{Enfoque metodológico de la investigación}

La presente investigación se enmarca en una \textit{investigación aplicada} con enfoque de diseño de artefactos software. El objetivo principal es construir y validar una arquitectura multiagente que permita gestionar comprobantes de pago y estimar gastos deducibles de manera conversacional.

Desde la perspectiva científica, se adopta un diseño cuasi-experimental: se construye el artefacto (sistema conversacional multiagente) y se evalúa su desempeño cuantitativo mediante métricas de precisión y latencia en tareas específicas (parseo, validación SUNAT y consulta). Los experimentos se realizan sobre un conjunto de comprobantes sintéticos y casos reales controlados, sin grupo de control basado en una arquitectura alternativa, dejando dicha comparación para trabajos futuros.

Desde la perspectiva de ingeniería, se sigue un proceso incremental compuesto por las siguientes etapas:

\begin{enumerate}
  \item Definición de requisitos funcionales y no funcionales, incluyendo restricciones tributarias, de seguridad y de experiencia de usuario.
  \item Diseño de la arquitectura general multiagente y del modelo de datos relacional.
  \item Implementación de los módulos de ingesta, OCR, agentes, backend y aplicación móvil.
  \item Diseño del protocolo experimental: construcción de datasets, definición de casos de prueba y métricas.
  \item Ejecución de experimentos y análisis de resultados.
\end{enumerate}

\section{Arquitectura general del sistema}

La arquitectura se organiza por funcionalidades (\textit{features}) y se compone de cuatro capas principales:

\begin{enumerate}
  \item \textbf{Capa de presentación}: aplicación móvil desarrollada con Expo/React Native, que expone interfaz de registro de comprobantes, vista de historial y chat con el asistente conversacional.
  \item \textbf{Capa de orquestación conversacional}: backend FastAPI que integra Agno (AgentOS) para definir y ejecutar agentes secuenciales y agentes basados en ReAct.
  \item \textbf{Capa de procesamiento de documentos}: módulo de OCR y extracción, que utiliza PyMuPDF para PDFs nativos y PP-OCRv5 para imágenes de boletas físicas.
  \item \textbf{Capa de persistencia}: base de datos PostgreSQL, accedida a través de repositorios que encapsulan el ORM y exponen una API orientada al dominio.
\end{enumerate}

En el contexto de Agno, el flujo de trabajo de ingesta se modela como un \textit{workflow} secuencial, mientras que el agente de consulta se implementa mediante el patrón ReAct, combinando razonamiento en lenguaje natural y llamadas a herramientas SQL deterministas.

En la tesis se recomienda incluir un diagrama de componentes que represente estas capas y su interacción, por ejemplo:

\begin{figure}[H]
  \centering
  \includegraphics[width=0.75\textwidth]{Figures/arquitectura_general.png}
  \caption{Arquitectura general del sistema conversacional multiagente.}
  \label{fig:arquitectura_general}
\end{figure}

\section{Arquitectura multiagente con Agno}

\subsection{Uso de Agno y justificación frente a LangGraph}

En la implementación se utiliza Agno como framework principal para la definición y ejecución de agentes. Agno provee un AgentOS que se integra de forma nativa con FastAPI, exponiendo endpoints para interactuar con agentes, gestionar sesiones, memoria y herramientas \parencite{agno2025framework}. Esta integración permite mantener una única aplicación backend coherente, donde los agentes conviven con el resto de endpoints de negocio.

LangGraph ofrece una abstracción basada en grafos para modelar aplicaciones con múltiples agentes y flujos complejos de decisión \parencite{langgraph2025graphapi}. Sin embargo, el flujo de ingesta y validación de comprobantes en este trabajo es esencialmente lineal y determinista: validar formato de archivo, aplicar OCR o extracción de texto, parsear, validar en SUNAT, clasificar y persistir. La complejidad adicional de un grafo de nodos y edges no se considera necesaria en esta etapa, y se prefiere una solución con flujos secuenciales explícitos y mayor cercanía a la lógica del dominio.

En síntesis, se elige Agno porque:

\begin{itemize}
  \item Permite definir \textit{workflows} secuenciales y equipos de agentes con bajo coste de configuración.
  \item Se integra de manera directa con FastAPI, facilitando la exposición de endpoints y el uso de middlewares de autenticación.
  \item Ofrece un modelo de ejecución \textit{private by design}, donde los agentes y sus datos corren íntegramente en la infraestructura controlada por el backend, protegiendo la información tributaria sensible.
\end{itemize}

\subsection{Agentes del workflow de ingesta}

El flujo de ingesta de comprobantes se implementa como una secuencia de agentes especializados:

\begin{enumerate}
  \item \textbf{Agente validador de comprobante}: verifica que el archivo subido sea un comprobante válido (tipo de archivo, número de páginas, tamaño, etc.) y genera un identificador de trabajo.
  \item \textbf{Agente de OCR y parseo}: aplica PyMuPDF o PP-OCRv5 según el tipo de documento, y luego utiliza un modelo de lenguaje para extraer un JSON estructurado con los campos del comprobante.
  \item \textbf{Agente validador SUNAT}: consulta el RUC del emisor mediante una herramienta externa (\texttt{consultar\_ruc}) y aplica reglas de deducibilidad basadas en el estado y condición del contribuyente y el código CIIU.
  \item \textbf{Agente clasificador}: asigna una categoría de gasto y un porcentaje de deducción aproximado en función de la normativa vigente y del CIIU detectado.
  \item \textbf{Agente de persistencia}: utiliza repositorios para almacenar comprobante, detalles, resultados de OCR, validaciones y clasificación en la base de datos.
\end{enumerate}

Estos agentes se conectan a través de un contexto compartido que encapsula el estado del trabajo de ingesta (identificador de usuario, comprobante, texto, resultados intermedios y errores). La secuencialidad favorece la trazabilidad, ya que cada etapa puede registrarse y auditarse por separado.

Para documentar este flujo, se recomienda incluir un diagrama de actividades o de flujo de procesos similar a:

\begin{figure}[H]
  \centering
  \includegraphics[width=0.75\textwidth]{Figures/flujo_ingesta.png}
  \caption{Flujo de trabajo de ingesta y validación de comprobantes.}
  \label{fig:flujo_ingesta}
\end{figure}

\subsection{Agente de consulta basado en ReAct}

El agente de consulta se implementa siguiendo el patrón ReAct \parencite{yao2023react}. En lugar de utilizar un esquema de Recuperación Aumentada (RAG) sobre embeddings, el agente trabaja con un conjunto de herramientas SQL deterministas que encapsulan consultas frecuentes sobre la base de datos, tales como:

\begin{itemize}
  \item Cálculo de montos totales por categoría y periodo.
  \item Listado de comprobantes por emisor o rango de fechas.
  \item Consultas sobre el porcentaje de deducción acumulado frente al tope de 3 UIT.
\end{itemize}

Dado un mensaje en lenguaje natural, el agente razona sobre la intención de la persona usuaria, selecciona la herramienta SQL apropiada y completa sus parámetros (por ejemplo, rango de fechas, categoría o emisor) en función del contenido de la consulta. El resultado de la herramienta se incorpora al contexto y el agente genera una respuesta final en lenguaje natural. Este enfoque evita complejidades asociadas al vectorizado del contenido y a la gestión de corpus extensos, aprovechando que los datos de interés se encuentran estructurados en la base de datos.

\section{Procesamiento de documentos: PyMuPDF y PP-OCRv5}

\subsection{Extracción de texto en boletas electrónicas con PyMuPDF}

Las boletas electrónicas descargadas de SUNAT comparten un formato PDF nativo en el que el texto se encuentra embebido de forma estructurada. Para este tipo de documentos, se utiliza PyMuPDF como motor de extracción, lo que permite recuperar el texto con alta velocidad y sin introducir errores de reconocimiento óptico de caracteres \parencite{pymupdf2025,artifex2025pymupdf}. Diversas evaluaciones independientes reportan que la extracción nativa con PyMuPDF es significativamente más rápida que métodos basados en OCR y que es adecuada para escenarios de alto volumen y baja latencia.

En el sistema propuesto, PyMuPDF se emplea como primera opción cuando se detecta que el PDF contiene texto embebido. Solo en caso de que la extracción falle o devuelva texto insuficiente se considera la posibilidad de aplicar OCR como respaldo. Esta estrategia reduce de manera importante el tiempo de procesamiento de boletas electrónicas y minimiza la propagación de errores de OCR hacia las etapas posteriores.

\subsection{OCR en boletas físicas con PP-OCRv5}

Para boletas físicas escaneadas o fotografiadas, se integra PP-OCRv5 como motor de OCR. Los modelos PP-OCRv5 se caracterizan por su tamaño reducido y por estar optimizados para despliegue en dispositivos y escenarios de producción donde la latencia es crítica \parencite{cui2025paddleocr30technicalreport}. La combinación de un detector de texto ligero con un reconocedor eficiente permite procesar imágenes de comprobantes con precisión suficiente para extraer campos como RUC, razón social, fecha y montos.

Se descartan, para este trabajo, modelos más pesados como PP-StructureV3 y PaddleOCR-VL, que se orientan a tareas de comprensión estructural o multimodal más complejas. Dado que las boletas de consumo presentan estructuras relativamente simples y que la prioridad es la velocidad, PP-OCRv5 ofrece un equilibrio adecuado entre rendimiento y consumo de recursos.

\section{Modelo de datos y patrón de repositorios}

\subsection{Modelo relacional en PostgreSQL}

El sistema utiliza PostgreSQL como gestor de base de datos relacional. El modelo de datos se centra en las siguientes entidades:

\begin{itemize}
  \item \textbf{Usuario}: almacena información básica de la persona usuaria y sus credenciales.
  \item \textbf{Emisor}: representa al contribuyente que emite el comprobante (RUC, razón social, nombre comercial, CIIU, estado y condición del RUC).
  \item \textbf{Comprobante}: contiene los datos principales del comprobante (tipo, serie, número, fecha, monto, moneda, origen, hashes de archivo, estado de procesamiento, flags de deducibilidad y duplicado).
  \item \textbf{Detalle\_comprobante}: almacena los ítems individuales del comprobante.
  \item \textbf{Validación}: registra los resultados de la consulta a SUNAT (estado y condición del RUC, CIIU detectado, coincidencia de nombres y regla de deducibilidad).
  \item \textbf{Clasificación}: guarda la categoría de gasto y el porcentaje de deducción asociado.
  \item \textbf{OCR\_pagina}: conserva el texto y una medida de confianza promedio para cada página OCR.
  \item \textbf{Estado\_trabajo}: gestiona el estado de los trabajos de ingesta o consulta.
  \item \textbf{Historial\_chat}: registra los mensajes intercambiados en la interfaz conversacional.
\end{itemize}

En la tesis se recomienda incluir un diagrama entidad–relación que represente estas tablas y sus relaciones, por ejemplo:

\begin{figure}[H]
  \centering
  \includegraphics[width=0.85\textwidth]{Figures/modelo_datos.png}
  \caption{Modelo entidad–relación de la base de datos del sistema.}
  \label{fig:modelo_datos}
\end{figure}

\subsection{Patrón de repositorios e inversión de dependencias}

Para desacoplar la lógica de negocio del ORM utilizado, se adopta el patrón de repositorios. Cada agregado principal (por ejemplo, \textit{Comprobante}, \textit{Emisor}, \textit{Usuario}) cuenta con una interfaz de repositorio que define operaciones orientadas al dominio (registrar un comprobante, buscar comprobantes por usuario y periodo, actualizar el resultado de validación, etc.). La implementación concreta de estas interfaces se realiza mediante el ORM, pero los agentes y servicios dependen únicamente de las abstracciones.

Este enfoque ofrece varias ventajas:

\begin{itemize}
  \item Facilita la prueba unitaria de la lógica de negocio, sustituyendo repositorios reales por dobles de prueba.
  \item Permite cambiar el ORM o incluso la tecnología de persistencia en el futuro sin modificar el código de los agentes.
  \item Expone operaciones semánticamente significativas, alineadas con el dominio tributario, en lugar de consultas SQL dispersas en el código.
\end{itemize}

\section{Backend y endpoints expuestos}

El backend se implementa con FastAPI y expone los siguientes endpoints principales:

\begin{itemize}
  \item \texttt{POST /api/v1/auth/register}: registra un nuevo usuario en el sistema, almacenando correo electrónico y contraseña en forma de hash.
  \item \texttt{POST /api/v1/auth/login}: autentica a la persona usuaria y entrega un token de acceso para invocar los demás endpoints.
  \item \texttt{POST /api/v1/comprobantes/subir}: recibe un comprobante en formato archivo (PDF o imagen) y dispara el workflow de ingesta, que ejecuta secuencialmente los agentes de validación de comprobante, OCR/parseo, validación SUNAT, clasificación y persistencia.
  \item \texttt{POST /api/v1/comprobantes/consultar}: recibe una consulta en lenguaje natural y delega al agente de consulta, el cual selecciona y ejecuta la herramienta SQL adecuada y devuelve una respuesta estructurada y una explicación en lenguaje natural.
\end{itemize}

Todos estos endpoints requieren autenticación y asocian la información procesada al usuario autenticado, garantizando aislamiento entre cuentas. La lógica de negocio se implementa en servicios y agentes, mientras que los controladores HTTP se limitan a gestionar validación básica de entrada, autenticación y manejo de errores.

\section{Aplicación móvil con Expo}

La capa de presentación se implementa como una aplicación móvil desarrollada con Expo sobre React Native. Expo provee un flujo administrado para construir aplicaciones multiplataforma (Android e iOS) desde una base de código única, con herramientas integradas para compilación en la nube, manejo de activos, notificaciones y actualizaciones OTA \parencite{expo2025ota,expo2025whyexpo}. Esto permite:

\begin{itemize}
  \item Reducir el tiempo de desarrollo y pruebas, ya que la mayoría de los cambios se concentran en el código JavaScript/TypeScript.
  \item Desplegar correcciones menores y mejoras en la interfaz mediante actualizaciones OTA, sin necesidad de pasar por todo el ciclo de revisión de las tiendas de aplicaciones para cada cambio.
  \item Integrar de manera sencilla la comunicación con el backend FastAPI, autenticación y almacenamiento local de sesiones.
\end{itemize}

La aplicación móvil implementa pantallas para el registro y autenticación de usuarios, la subida de comprobantes (seleccionando archivos o capturando fotografías) y un módulo de chat donde la persona usuaria puede realizar consultas en lenguaje natural sobre sus gastos y deducciones acumuladas.

\section{Conjunto de evaluación y métricas}

Para evaluar empíricamente el desempeño de la arquitectura propuesta se definen tres experimentos principales, cada uno alineado con un objetivo específico:

\begin{enumerate}
  \item \textbf{Evaluación del agente de parseo}: se construye un conjunto de 20 comprobantes sintéticos, en formato JSON, que contienen texto OCR simulado con variaciones en la forma de referirse al cliente y al emisor, así como en la estructura de los ítems. Se mide la latencia promedio de cada modelo, la tasa de éxito en la generación de JSON válido y la precisión en la extracción de campos clave.
  \item \textbf{Evaluación del agente validador SUNAT}: se diseñan 5 casos de prueba con RUC reales que cubren combinaciones de estado y condición del contribuyente, así como diferentes actividades económicas. Se evalúa la capacidad de los modelos para invocar correctamente la herramienta de consulta de RUC y para extraer campos como estado, condición y código CIIU.
  \item \textbf{Evaluación del agente de consulta}: se definen 4 consultas de prueba con diferentes niveles de complejidad (cálculo de totales, filtrado por fechas, búsqueda por emisor e inferencia de fechas relativas), y se mide la precisión en la selección de la herramienta SQL adecuada, la precisión en el llenado de argumentos y la latencia.
\end{enumerate}

Las métricas seleccionadas son:

\begin{itemize}
  \item \textbf{Latencia}: tiempo, en segundos, entre la recepción de la solicitud y la producción de la respuesta del agente.
  \item \textbf{Tasa de éxito}: proporción de ejecuciones en las que el formato de salida del agente es válido y procesable por las etapas siguientes (por ejemplo, JSON sintácticamente correcto).
  \item \textbf{Precisión de campos}: fracción de campos correctamente extraídos o inferidos respecto de la \textit{ground truth} definida para cada caso de prueba.
\end{itemize}

Los resultados de estos experimentos se presentan y discuten en el Capítulo~\ref{cap:resultados}.
